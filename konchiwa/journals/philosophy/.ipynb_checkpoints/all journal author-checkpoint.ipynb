{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Matthew Mandelkern', 'Jacob M. Nebel', 'Dennis Schulting', 'Julie K. Ward', 'Alex Madva', 'Matthew S. Bedke', \"Casey O'Callaghan\", 'Neil Mehta', 'Robert J. Howell', 'István Aranyosi']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#雑誌タイトル\\ntitle = \"The Philosophical Review\"\\n#print(title)\\n#論文タイトル\\naa = soup.find_all(class_=\"customLink item-title\")\\narticles = []\\nfor a in aa:\\n    articles.append(a.getText().replace(\"\\n\",\"\").strip(\" \"))\\n#print(articles)\\n#url\\nurls = []\\nbb = soup.find_all(class_=\"customLink item-title\")\\nfor b in bb:\\n    cc = b.find_all(\\'a\\')\\n    for c in cc:\\n        d = c.get(\\'href\\')\\n        e = \\'https://read.dukeupress.edu\\' + d\\n        urls.append(e)\\n#print(urls)\\n\\nimage = soup.find(class_=\"fb-featured-image\")\\nimg = image.get(\\'src\\')\\n   \\n\\n\\n\\nprint(img)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from django.shortcuts import render\n",
    "import lxml\n",
    "\n",
    "\n",
    "ID = 'PhilosRev'\n",
    "pub = 'Duke University Press'\n",
    "j_url = \"https://read.dukeupress.edu/the-philosophical-review/issue/128/1\" \n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0\",\n",
    "    }\n",
    "HP = requests.get(j_url, headers=headers)\n",
    "soup = BeautifulSoup(HP.text, \"html.parser\")\n",
    "\n",
    "authors = []\n",
    "auths = soup.find_all(class_=\"al-authors-list\")\n",
    "for auth in auths:\n",
    "    authors.append(auth.getText().strip())\n",
    "print(authors)\n",
    "\n",
    "\"\"\"\n",
    "#雑誌タイトル\n",
    "title = \"The Philosophical Review\"\n",
    "#print(title)\n",
    "#論文タイトル\n",
    "aa = soup.find_all(class_=\"customLink item-title\")\n",
    "articles = []\n",
    "for a in aa:\n",
    "    articles.append(a.getText().replace(\"\\n\",\"\").strip(\" \"))\n",
    "#print(articles)\n",
    "#url\n",
    "urls = []\n",
    "bb = soup.find_all(class_=\"customLink item-title\")\n",
    "for b in bb:\n",
    "    cc = b.find_all('a')\n",
    "    for c in cc:\n",
    "        d = c.get('href')\n",
    "        e = 'https://read.dukeupress.edu' + d\n",
    "        urls.append(e)\n",
    "#print(urls)\n",
    "\n",
    "image = soup.find(class_=\"fb-featured-image\")\n",
    "img = image.get('src')\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "print(img)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Johan E. Gustafsson', 'Nathan Robert Howard, N. G. Laskowski', 'J. Adam Carter, Jesper Kallestrup', 'Martin Fischer, Leon Horsten, Carlo Nicolai', 'Patrick Todd, Brian Rabern', 'James Pryor', 'Adam Elga', 'Jakob Hohwy', 'Shaun Nichols, Joshua Knobe', 'Sally Haslanger']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "ID = 'Nous'\n",
    "pub = 'Wiley'\n",
    "j_url = \"https://onlinelibrary.wiley.com/journal/14680068\" \n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0\",\n",
    "    }\n",
    "HP = requests.get(j_url, headers=headers)\n",
    "soup = BeautifulSoup(HP.text, \"html.parser\")\n",
    "\n",
    "authors = []\n",
    "auths = soup.find_all(\"ul\", class_=\"rlist--inline loa comma\")\n",
    "for auth in auths:\n",
    "    authors.append(auth.getText().strip().replace(\"\\n\", ', '))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['阿部 里加', '飯泉 佑介', '岡崎 秀二郎', '小原 拓磨', '川島 彬', '酒井 健太朗', '佐藤 大介', '寺嶋 雅彦', '本間 裕之', '山蔦 真之']\n"
     ]
    }
   ],
   "source": [
    "ID = 'Tetsugaku'\n",
    "pub = '日本哲学会'\n",
    "j_url = \"https://www.jstage.jst.go.jp/browse/philosophy/list/-char/ja\" \n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0\",\n",
    "    }\n",
    "HP = requests.get(j_url, headers=headers)\n",
    "HP_text = (HP.text.split('応募論文'))\n",
    "soup = BeautifulSoup(HP_text[1], \"html.parser\")\n",
    "soup2 = BeautifulSoup(HP.text, \"html.parser\")\n",
    "\n",
    "\n",
    "authors = []\n",
    "auths = soup.find_all(class_=\"searchlist-authortags customTooltip\")\n",
    "for auth in auths:\n",
    "    authors.append(auth.getText())\n",
    "print(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Warren S Goldstein, Rebekka King, Jonathan Boyarin', ' Rosario Forlenza, Bryan S Turner', ' Mitsutoshi Horii', ' Colin Powers', ' Victor Counted', ' Robin D Willey']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from django.shortcuts import render\n",
    "import lxml\n",
    "\n",
    "\n",
    "ID = 'CRR'\n",
    "pub = 'SAGE'\n",
    "j_url = \"https://journals.sagepub.com/toc/crra/7/1\" \n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0\",\n",
    "    }\n",
    "HP = requests.get(j_url, headers=headers)\n",
    "HP_text = HP.text.split('Book Reviews')\n",
    "soup = BeautifulSoup(HP.text, \"html.parser\")\n",
    "soup2 = BeautifulSoup(HP_text[0+1], \"html.parser\")\n",
    "\n",
    "authors = []\n",
    "auths = soup2.find_all(class_=\"articleEntryAuthor all\")\n",
    "for auth in auths:\n",
    "    authors2 = []\n",
    "    au = auth.find_all(class_=\"header\")\n",
    "    for a in au:\n",
    "        authors2.append(a.getText().replace(\"Search Google Scholar\",'').replace(\"for this author\",'').replace(\"See all articles by this author\",''))\n",
    "        b = ','.join(authors2)\n",
    "    authors.append(b)\n",
    "print(authors)\n",
    "    \n",
    "        \n",
    "        \n",
    "    #authors.append(authors2)\n",
    "    #for aut in authors:\n",
    "    #    print(aut)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hugh Nicholson', 'Markus Dressler', 'Christopher B. Zeichmann']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nauths = soup.find_all(class_=\"articleEntryAuthor all\")\\nfor auth in auths:\\n    authors2 = []\\n    au = auth.find_all(class_=\"header\")\\n    for a in au:\\n        authors2.append(a.getText().replace(\"Search Google Scholar\",\\'\\').replace(\"for this author\",\\'\\').replace(\"See all articles by this author\",\\'\\'))\\n        b = \\',\\'.join(authors2)\\n    authors.append(b)\\nprint(authors)\\n\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID = 'MTSR'\n",
    "pub = 'Brill'\n",
    "j_url = \"https://brill.com/view/journals/mtsr/mtsr-overview.xml\"\n",
    "a_url = \"https://brill.com/abstract/journals/mtsr/31/2/mtsr.31.issue-2.xml\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0\",\n",
    "    }\n",
    "\n",
    "HP = requests.get(a_url, headers=headers)\n",
    "soup = BeautifulSoup(HP.text, 'lxml')\n",
    "\n",
    "\n",
    "authors = []\n",
    "auths = soup.find_all(class_=\"c-Button--link c-Button--primary\")\n",
    "for auth in auths[1:-1]:\n",
    "    authors.append(auth.getText())\n",
    "print(authors)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "auths = soup.find_all(class_=\"articleEntryAuthor all\")\n",
    "for auth in auths:\n",
    "    authors2 = []\n",
    "    au = auth.find_all(class_=\"header\")\n",
    "    for a in au:\n",
    "        authors2.append(a.getText().replace(\"Search Google Scholar\",'').replace(\"for this author\",'').replace(\"See all articles by this author\",''))\n",
    "        b = ','.join(authors2)\n",
    "    authors.append(b)\n",
    "print(authors)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theorizing religious socialization: a critical assessment\n",
      "Primary religious socialization agents and young adults’ understanding of religion: connections and disconnections\n",
      "The role of grandmothers in the religious socialization of young adults in post-socialist Russia and Poland\n",
      "Two cases of religious socialization among minorities\n",
      "From socialization to self-socialization? Exploring the role of digital media in the religious lives of young adults in Ghana, Turkey, and Peru\n",
      "Religious socialization of non-religious university students\n",
      "Textbooks on ‘Hinduism’: defining an ocean described from myriad shores\n",
      "Textbooks for teaching the sociology of religion\n",
      "https://www.tandfonline.com/doi/full/10.1080/0048721X.2019.1584349\n",
      "https://www.tandfonline.com/doi/full/10.1080/0048721X.2019.1584350\n",
      "https://www.tandfonline.com/doi/full/10.1080/0048721X.2019.1584351\n",
      "https://www.tandfonline.com/doi/full/10.1080/0048721X.2019.1584352\n",
      "https://www.tandfonline.com/doi/full/10.1080/0048721X.2019.1584353\n",
      "https://www.tandfonline.com/doi/full/10.1080/0048721X.2019.1584355\n",
      "https://www.tandfonline.com/doi/full/10.1080/0048721X.2018.1501872\n",
      "https://www.tandfonline.com/doi/full/10.1080/0048721X.2018.1505112\n",
      "['Maria Klingenberg & Sofia Sjö', 'Ben-Willie Kwaku Golo, Måns Broo, Sławomir Sztajer, Francis Benyah, Sohini Ray & Mallarika Sarkar', 'Polina Vrublevskaya, Marcus Moberg & Sławomir Sztajer', 'Måns Broo, Sawsan Kheir & Mallarika Sarkar', 'Marcus Moberg, Sofia Sjö, Ben-Willie Kwaku Golo, Habibe Erdiş Gökçe, Rafael Fernández Hart, Sidney Castillo Cardenas, Francis Benyah & Mauricio Javier Villacrez Jó', 'Karoliina Dahl, Nurit Novis-Deutsch, Maria Klingenberg, Janne Kontala, Sławomir Sztajer & Avivit Mussel', 'Peter Gottschalk', 'Abby Day']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "ID = 'Reli'\n",
    "pub = 'Routledge'\n",
    "j_url = \"https://www.tandfonline.com/toc/rrel20/current\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0\",\n",
    "    }\n",
    "HP = requests.get(j_url, headers=headers)\n",
    "HP_text = HP.text.split('Book Reviews')\n",
    "soup = BeautifulSoup(HP.text, \"html.parser\")\n",
    "soup2 = BeautifulSoup(HP_text[0], \"html.parser\")\n",
    "\n",
    "\n",
    "articles = []\n",
    "p_titles = soup2.find_all(class_=\"art_title linkable\")\n",
    "for p_title in p_titles:\n",
    "    print(p_title.getText())\n",
    "       \n",
    "\n",
    "authors = []\n",
    "abab = soup2.find_all(class_=\"articleEntryAuthor all\")\n",
    "for ab in abab:\n",
    "    authors.append(ab.getText().replace(\"\\n\",''))\n",
    "    \n",
    "for p_title in p_titles:\n",
    "        b = p_title.find('a').get('href')\n",
    "        c = 'https://www.tandfonline.com' + b\n",
    "        print(c)\n",
    "                    \n",
    "print(authors)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Columns in Context: Venerable Monuments and Landscapes of Memory in Early India', 'The Non-Immanent Frame: Medicine as Ethics in the Islamic Modernist Movement of Late Colonial Indonesia', 'Science, Sorcery, and Secrets in the Fawāʾid Nūrāniyya of Sīdi Muḥammad Al-Kuntī']\n",
      "['Elizabeth A. Cecil,Peter C. Bisschop', 'Kevin E. Ko', 'Ariela Marcus-Sells']\n"
     ]
    }
   ],
   "source": [
    "ID = 'HR'\n",
    "j_url = \"https://www.journals.uchicago.edu/toc/hr/current\" \n",
    "headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0\",\n",
    "        }\n",
    "HP = requests.get(j_url, headers=headers)\n",
    "HP_text = HP.text.split('Book Reviews')\n",
    "soup = BeautifulSoup(HP_text[0], \"html.parser\")\n",
    "\n",
    "#雑誌のタイトル\n",
    "publisher = soup.find_all(class_=\"menu-section\")[1].string\n",
    "title = soup.find('em').string\n",
    "#return (title)\n",
    "\n",
    "#論文のタイトル\n",
    "articles = []\n",
    "papers = soup.find_all(class_=\"hlFld-Title\")\n",
    "for paper in papers[2:]:\n",
    "    paper_titles = paper.getText()\n",
    "    articles.append(paper_titles)\n",
    "print(articles)\n",
    "\n",
    "authors = []\n",
    "abab = soup.find_all(\"tr\")\n",
    "for ab in abab:\n",
    "    authors2 = []\n",
    "    bb = ab.find_all(class_=\"hlFld-ContribAuthor\")\n",
    "    for a in bb:   \n",
    "        authors2.append(a.getText())\n",
    "    b = ','.join(authors2)\n",
    "    authors.append(b)\n",
    "authors = list(filter(lambda str:str != '', authors))\n",
    "\n",
    "    \n",
    "print(authors)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['中村 友香', '川本 直美']\n"
     ]
    }
   ],
   "source": [
    "ID = 'Bunka_jinrui'\n",
    "pub = '日本文化人類学会'\n",
    "j_url = \"https://www.jstage.jst.go.jp/browse/jjcanth/list/-char/ja\" \n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0\",\n",
    "    }\n",
    "HP = requests.get(j_url, headers=headers)\n",
    "HP_text = (HP.text.split('特集'))\n",
    "soup = BeautifulSoup(HP_text[0], \"html.parser\")\n",
    "soup2 = BeautifulSoup(HP.text, \"html.parser\")\n",
    "\n",
    "\n",
    "\n",
    "authors = []\n",
    "auths = soup.find_all(class_=\"searchlist-authortags customTooltip\")\n",
    "for auth in auths:\n",
    "    authors.append(auth.getText())\n",
    "authors = list(filter(lambda str:str != '', authors))\n",
    "print(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cultural Anthropology\n",
      "['Zambian Children’s Imaginal Caring: On Fantasy, Play, and Anticipation in an Epidemic', 'Animating Relations: Digitally Mediated Intimacies between the Living and the Dead', 'The Limits of Dwelling and the Unwitnessed Death', 'A Disarmament Program for Witches: The Prospective Politics of Antiwitchcraft, Postwarcraft, and Rebrandcraft in Sierra Leone', 'The Subject of Wrongs: Crime, Populism, and Venezuela’s Punitive Turn']\n",
      "['https://journal.culanth.org/index.php/ca/article/view/3915', 'https://journal.culanth.org/index.php/ca/article/view/3954', 'https://journal.culanth.org/index.php/ca/article/view/3855', 'https://journal.culanth.org/index.php/ca/article/view/3955', 'https://journal.culanth.org/index.php/ca/article/view/3858']\n",
      "['Jean Hunleth', 'Molly Hales', 'Jason Danely', 'Samuel Mark Anderson', 'Robert Samet']\n",
      "https://journal.culanth.org/public/journals/1/cover_issue_53_en_US.jpg\n"
     ]
    }
   ],
   "source": [
    "ID = 'CA'\n",
    "pub = 'The Society for Cultural Anthropology'\n",
    "j_url = \"https://journal.culanth.org/index.php/ca\" \n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0\",\n",
    "    }\n",
    "HP = requests.get(j_url, headers=headers)\n",
    "HP_text = HP.text.split(\"Curated Collections\")\n",
    "soup = BeautifulSoup(HP.text, \"html.parser\")\n",
    "soup2 = BeautifulSoup(HP_text[1], \"html.parser\") \n",
    "\n",
    "\n",
    "#雑誌タイトル\n",
    "title = 'Cultural Anthropology'\n",
    "\n",
    "print(title)\n",
    "#論文タイトル\n",
    "aa = soup2.find_all(\"h3\")\n",
    "articles = []\n",
    "for a in aa:\n",
    "    articles.append(a.getText().replace('\\n','').replace('\\t','').replace(\"HTML\",'').replace(\"PDF\",'').replace(\"EPUB\",''))\n",
    "print(articles)\n",
    "\n",
    "#url\n",
    "urls = []\n",
    "bb = soup2.find_all(\"h3\")\n",
    "for b in bb:\n",
    "    cc = b.find_all('a')\n",
    "    for c in cc:\n",
    "        d = c.get('href')\n",
    "        urls.append(d)\n",
    "print(urls)\n",
    "\n",
    "\n",
    "authors = []\n",
    "auths = soup.find_all()\n",
    "for auth in auths:\n",
    "    authors.append(auth.getText())\n",
    "    \n",
    "    \n",
    "authors = []\n",
    "abab = soup.find_all(\"div\", class_=\"article_summary__content\")\n",
    "for ab in abab:\n",
    "    authors2 = []\n",
    "    bb = ab.find_all(class_=\"name\")\n",
    "    for a in bb:   \n",
    "        authors2.append(a.getText())\n",
    "    b = ','.join(authors2)\n",
    "    authors.append(b.replace('\\n','').replace('\\t',''))\n",
    "\n",
    "\n",
    "print(authors)\n",
    "\n",
    "image = soup2.find(class_=\"issue__cover\")\n",
    "img = image.get('src')\n",
    "\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Don Brenneis and Karen B. Strier', 'Richard Bauman', 'Cristóbal Gnecco', 'Alfredo González-Ruibal', 'Reinhard Bernbeck', 'Erik Otárola-Castillo and Melissa G. Torquato', 'Alex W. Barker', 'Francis P. McManamon', 'Joanna Radin', 'Clark Spencer Larsen', 'Catherine M. Hill', 'Richard R. Lawler', 'Jason M. Kamilar and Lydia Beaudrot', 'Erin P. Riley and Michelle Bezanson', 'Richard B. Lee', 'Rebecca J. Lewis', 'Martha Sif Karrebæk, Kathleen C. Riley, Jillian R. Cavanaugh', 'Christopher Ball', 'Steven P. Black', 'Courtney Handman', 'Inmaculada M. García-Sánchez', 'Tanja Petrović', 'Miyako Inoue', 'Adam Reed', 'Jerry K. Jacka', 'Stefan Helmreich and Caroline A. Jones', 'Anne Meneley', 'Jeffrey T. Martin', 'Alex Blanchette', 'Shaila Seshia Galvin', 'Nikolai Ssorin-Chaikov', 'Shaylih Muehlmann', 'Clara Han', 'Cheryl Mattingly and Jason Throop']\n"
     ]
    }
   ],
   "source": [
    "ID = 'annurev-anthro'\n",
    "j_url = \"https://www.annualreviews.org/toc/anthro/current\" \n",
    "headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0\",\n",
    "        }\n",
    "HP = requests.get(j_url, headers=headers)\n",
    "HP_text = HP.text.split('About This Journal')\n",
    "soup = BeautifulSoup(HP_text[0], \"html.parser\")\n",
    "\n",
    "authors = []\n",
    "auths = soup.find_all(class_=\"text\")\n",
    "for auth in auths:\n",
    "    abab = auth.find_all(\"p\")\n",
    "    for ab in abab:\n",
    "        authors.append(ab.getText()[:ab.getText().find('Vol')])\n",
    "authors = list(filter(lambda str:str != '', authors))\n",
    "print(authors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
